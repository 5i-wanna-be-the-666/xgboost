{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import inspect\n",
    "\n",
    "print(inspect.getfile(xgb.train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from dataset.load_dat import load_keel_dat\n",
    "from kmeans_smote import KMeansSMOTE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# **åŠ è½½æ•°æ®é›†ï¼ˆä»¥ glass1 æ•°æ®é›†ä¸ºä¾‹ï¼‰**\n",
    "def load_keel(name):\n",
    "    # ä» UCI æˆ–æœ¬åœ°åŠ è½½ 'glass1' æ•°æ®é›†\n",
    "    # ä¸‹è½½åœ°å€: https://sci2s.ugr.es/keel/dataset/data/classification/glass1.zip\n",
    "    # å‡è®¾æ•°æ®å·²ç»ä¿å­˜ä¸º glass1.csv\n",
    "    data = load_keel_dat(\"dataset/\"+name)  # æ›¿æ¢ä¸ºå®é™…è·¯å¾„\n",
    "    print(data)\n",
    "    X = data.iloc[:, :-1].values  # ç‰¹å¾\n",
    "    y = data.iloc[:, -1].values   # æ ‡ç­¾\n",
    "    return X, y\n",
    "\n",
    "# ä¸»æµç¨‹ï¼ˆK æŠ˜ï¼‰\n",
    "def main():\n",
    "    #name = \"abalone19.dat\" #scale_pos_weight=0.1\n",
    "    name = \"yeast6.dat\"\n",
    "    X, y = load_keel(name)\n",
    "    print(X.shape)\n",
    "    print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sdv.single_table import CTGANSynthesizer, TVAESynthesizer\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "import torch\n",
    "\n",
    "def generate_synthetic_samples(X, y, class_value=1, n_samples=500, method='ctgan', epochs=300):\n",
    "\n",
    "    # æ£€æŸ¥ GPU\n",
    "    has_cuda = torch.cuda.is_available()\n",
    "    print(f\"ğŸš€ GPU å¯ç”¨: {has_cuda}\")\n",
    "\n",
    "    # è½¬ DataFrame\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        X = pd.DataFrame(X, columns=[f'f{i}' for i in range(X.shape[1])])\n",
    "    y = pd.Series(y, name='label')\n",
    "\n",
    "    # è·å–ç›®æ ‡ç±»æ•°æ®\n",
    "    real_data = X.copy()\n",
    "    real_data['label'] = y\n",
    "    real_data = real_data[real_data['label'] == class_value].reset_index(drop=True)\n",
    "\n",
    "    # Metadata\n",
    "    metadata = SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(real_data)\n",
    "\n",
    "    # åˆå§‹åŒ–æ¨¡å‹\n",
    "    if method.lower() == 'ctgan':\n",
    "        model = CTGANSynthesizer(\n",
    "            metadata,\n",
    "            epochs=epochs,\n",
    "            verbose=True,\n",
    "            cuda=has_cuda  # âœ… æ­£ç¡®æ–¹å¼\n",
    "        )\n",
    "    elif method.lower() == 'tvae':\n",
    "        if has_cuda:\n",
    "            print(\"âš ï¸ TVAE æš‚ä¸æ”¯æŒ GPUï¼Œå°†ä½¿ç”¨ CPU\")\n",
    "        model = TVAESynthesizer(\n",
    "            metadata,\n",
    "            epochs=epochs,\n",
    "            verbose=True\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'ctgan' or 'tvae'\")\n",
    "\n",
    "    # æ‹Ÿåˆæ¨¡å‹\n",
    "    print(f\"ğŸ“¦ å¼€å§‹è®­ç»ƒ {method.upper()} æ¨¡å‹ï¼Œå…± {epochs} è½®\")\n",
    "    model.fit(real_data)\n",
    "    print(\"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ\")\n",
    "\n",
    "    # åˆæˆæ•°æ®\n",
    "    condition = {'label': class_value}\n",
    "    synthetic_data = model.sample(num_rows=n_samples, conditions=[condition])\n",
    "\n",
    "    synthetic_X = synthetic_data.drop(columns='label')\n",
    "    synthetic_y = synthetic_data['label']\n",
    "\n",
    "    return synthetic_X, synthetic_y, synthetic_data, real_data, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ GPU å¯ç”¨: False\n",
      "ğŸ“¦ å¼€å§‹è®­ç»ƒ CTGAN æ¨¡å‹ï¼Œå…± 200 è½®\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sdv.evaluation.single_table import evaluate_quality\n",
    "\n",
    "# æ¨¡æ‹Ÿæ•°æ®\n",
    "X, y = make_classification(n_samples=1000, n_features=20, weights=[0.95, 0.05], random_state=42)\n",
    "\n",
    "# ç”Ÿæˆå¼‚å¸¸ç±»ï¼ˆclass 1ï¼‰æ ·æœ¬\n",
    "synthetic_X, synthetic_y, synthetic_data, real_data, metadata = generate_synthetic_samples(\n",
    "    X, y, class_value=1, n_samples=500, method='ctgan', epochs=200\n",
    ")\n",
    "\n",
    "# SDV è´¨é‡è¯„ä¼°\n",
    "score = evaluate_quality(real_data=real_data, synthetic_data=synthetic_data, metadata=metadata)\n",
    "print(\"ğŸ“Š SDV è´¨é‡è¯„åˆ†:\", round(score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhy_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
